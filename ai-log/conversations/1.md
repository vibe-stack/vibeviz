Task: build a complete, production-ready node-based visual/audio patching app in Next.js, inspired by TouchDesigner, using React Flow for the unified editor, R3F for 3D rendering with TSL (Three.js NodeMaterials for pluggable shader graphs), and Tone.js for audio synthesis. Enable users to create/connect Shader Nodes (texture modifiers), Channel Nodes (agnostic signal processors like LFOs, noise, math ops on numeric channels that drive visuals/audio), and Audio Nodes (synth-specific), compile into a single synchronized runtime pipeline, and render unified 60fps visuals/audio.

Functional Requirements:
- Split-screen layout: Left 70% React Flow editor for unified nodes/edges (mix of shader/channel/audio types); right 30% R3F Canvas for live output.
- Unified Node system: Base Node interface with inputs/outputs; Shader Nodes (e.g., Noise via TSL MathNode/ColorNode, Blur, Color Grade) output TSL Nodes for chaining in NodeMaterial; Channel Nodes (agnostic signals: e.g., LFO, Perlin noise, Math ops, FFT from audio) output numeric channels/sequences that propagate to TSL inputs (uniforms) or Tone params (modulation); Audio Nodes (e.g., Oscillator, Gain, Filter) use Tone.Signal/Waveform and accept channel modulation via .connect() or param ramps.
- Leverage React Flow's computing flows (useNodeConnections, useNodesData, updateNodeData) for lazy topological value propagation/caching across domains (e.g., channel float -> TSL uniformNode or audio frequency ramp).
- Graph compilation: Continuously recompiles on changes, traverse unified DAG to build TSL NodeMaterial pipeline (channel signals as dynamic uniform inputs) and Tone.js graph (channels modulating synth params, e.g., LFO to filter freq); render final TSL as full-screen quad in R3F.
- Synchronization: Tone.Transport as master clock; schedule audio/channel events with scheduleOnce/Repeat; sync visuals via Tone.Draw.schedule() for RAF callbacks (e.g., channel pulse -> TSL uniform at audio time); useFrame for mutations with drift correction via getSecondsAtTime.
- Performance: Mutate in useFrame/useRef (no React state for hot paths); Tone.Context.latencyHint='interactive'; resume on visibilitychange; implement instancing (InstancedMesh), LOD (from drei), batching (BufferGeometryUtils), frame capping (RAF delta >1000/60), offscreen workers for non-GPU evals; ensure <16ms/frame.
- User gesture: Await Tone.start() on run; handle empty graph as noop, prevent cycles via React Flow.

User Interactions:
- Drag/add custom nodes (Shader/Channel/Audio types) in React Flow editor; connect ports via handles (CustomHandle for isolated states, e.g., channel out -> shader input or audio mod).
- Click "Play / Pause" toolbar button to evaluate unified graph, start Tone.Transport, and trigger live rendering/playback.
- Interact with live output: Audio plays to speakers; visuals update in real-time (e.g., channel LFO driving TSL color intensity or audio freq).
- Edit node params (e.g., rate slider on Channel LFO) to propagate via computing flows and reflect in runtime across domains.
- Numeric values in nodes can directly be edited with the drag-input in the codebase (exists)
- have a floating panel on the left to add nodes, sort them by categories (Texture [Shaders], Channel [Audio/Motion], Model [3D models and primitives])

Data Requirements:
- Nodes/edges from React Flow state (initial sample nodes: 3-4 each type, e.g., LFO channel modulating shader blur).
- Computed values: Lazy-cached in node.data via updateNodeData (e.g., channel sequences as arrays/floats for TSL uniformNode or Tone rampTo).
- Runtime: Refs for hot data (TSL nodes, Tone objects, channel signals); compile from unified graph traversal.

State Management:
- Valtio for global cold data (nodes/edges positions/structure); local refs/external objects for hot paths (TSL uniforms: {value: {time:0}}, Tone signals, channel values) to avoid re-renders.
- Persistent: None required; cache computed node.data locally in-memory via computing flows (replace: true for overwrites).
- No global hot state; keep UI declarative, runtime imperative.

Notes: Use Next.js for the app; adhere to dark, calming, minimalistic, rounded UI (e.g., CSS vars for #1a1a1a bg, #f0f0f0 accents, border-radius: 8px). Colocate files by features (e.g., channel-node folder with component + hook). Write small modular files (e.g., separate unified-compiler-hook.ts). Prefer dedicated colocated hooks (e.g., use-channel-propagation.ts) over inline. Focus on modularity for extension; include example TSL/channel setups (e.g., mathNode mul for LFO pulse). Mimic TouchDesigner CHOPs: Channels as agnostic numeric sequences driving cross-domain params. Test on mid-range devices; handle mobile perf throttling.

Sidequest: Add 1-2 sample unified patches (e.g., channel LFO driving TSL noise intensity and audio filter cutoff) loadable on app start for demo.

Notes: Use Next.js for the app; adhere to dark, calming, minimalistic, rounded UI. Colocate files by features (e.g., shader-node folder with component + hook). Write small modular files (e.g., separate tone-sync-hook.ts). Prefer dedicated colocated hooks (e.g., use-tsl-compiler.ts) over inline. Focus on modularity for extension;